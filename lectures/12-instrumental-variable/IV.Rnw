\documentclass[fleqn]{beamer}

% \usefonttheme[onlylarge]{structuresmallcapsserif}
\usefonttheme[onlysmall]{structurebold}
\usepackage[normalem]{ulem} % use normalem to protect \emph
\newcommand\hl{\bgroup\markoverwith
  {\textcolor{yellow}{\rule[-.5ex]{2pt}{2.5ex}}}\ULon}
\usepackage{amsmath,amssymb}
\usepackage{tikz-cd}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage[all]{xy}
\usepackage{lscape}
\usepackage[authoryear]{natbib}
\usepackage{array}
\usepackage{listings}
\usepackage{wasysym}
\usepackage{url}
\usepackage{multirow}
\usepackage{color}
\usepackage{qtree}
\usepackage[absolute,overlay]{textpos}
\usepackage{inconsolata}
\usepackage{framed}
\definecolor{shadecolor}{rgb}{1,0.8,0.3}
\usepackage[justification=centering]{caption}
\captionsetup{compatibility=false}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue}
\usepackage[space]{grffile}
\usefonttheme[onlymath]{serif}
% \usepackage{tikz}
% \usetikzlibrary{calc,matrix}
\usepackage{sgame}
\usepackage{tikz}
\usetikzlibrary{trees}

\mode<presentation>
%\usetheme{Frankfurt}
\usetheme{boxes}
\usecolortheme{beaver}
%\usetheme{Singapore}
%\usetheme{Hannover}

\newcommand*{\captionsource}[2]{%
  \caption[{#1}]{%
    #1%
    \\\hspace{\linewidth}%
    {\small\textbf{Source:} #2}%
  }%
}

\beamertemplatenavigationsymbolsempty
\setbeamertemplate{blocks}[rounded]
\newenvironment<>{block_code}[1]{%
  \setbeamercolor{block title}{fg=white,bg=black}%
  \begin{block}#2{#1}}{\end{block}}

%--------------------------
% Reduce the spacing between R code and output
%--------------------------
\usepackage{etoolbox} 
\makeatletter 
\preto{\@verbatim}{\topsep=0pt \partopsep=0pt } 
\makeatother

\renewenvironment{knitrout}{\setlength{\topsep}{0mm}}{} 

%===================================
% Coloring change
%===================================
\definecolor{darkred}{rgb}{0.8,0,0}
\setbeamercolor{block title}{fg=darkred,bg=structure.fg!20!bg!50!bg}
\setbeamercolor{block body}{use=block title,bg=block title.bg}

\title{Instrumental Variable (IV) Estimation}
\author{Taro Mieno}
\date{AECN 896-003: Applied Econometrics}
\everymath{\displaystyle}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

<<prep, echo=FALSE, message=F, warning=F>>=
source('~/Box Sync/R_libraries_load/library.R')
library(stargazer)
library(readstata13)
library(AER)
# source('~/Box Sync/MySoftware/MyR/ggplot2/ggplot2_default_teaching.R')
source('~/Box Sync/Teaching/R_functions/functions.R')
opts_chunk$set(
  comment = NA,
  message = FALSE,
  warning = FALSE,
  tidy=FALSE,
  size='footnotesize',
  #--- figure related ---#
  fig.align='center',
  out.height='2.5in',
  out.width='2.5in',
  dev='pdf'
  )
setwd('~/Box Sync/Teaching/UNL/EconometricsMaster/aecn892_2017/Lectures/Endogeneity')
@

%===================================
% Functional Form
%===================================

\begin{frame}[c,fragile]
  \begin{block}{Motivation: Omitted Variables}  
    \begin{itemize}
       \item ignore the problem and suffer the consequence
       \item find a suitable proxy and use the plug-in method 
       \item use FE or FD estimators if you have panel data, which works as long as the unobservables are time-invariant
       \item \textcolor{blue}{instrumental variable estimation}
     \end{itemize} 
  \end{block}
\end{frame}

\begin{frame}[c]
  \begin{block}{The Model}  
  \begin{align*}
    y=\beta_0 + \beta_1 x_1 + \beta_2 x_2 + u
  \end{align*}
  \vspace{-0.6cm}
  \begin{itemize}
    \item $x_1$ is endogenous: $E[u|x_1] \ne 0$ (or $Cov(u,x_1)\ne 0$)
    \item $x_2$ is exogenous: $E[u|x_1] = 0$ (or $Cov(u,x_1) = 0$)
  \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[c]
  \begin{block}{Idea: very loosely put}  
    Bring in variable(s) (\textcolor{blue}{Instrumental variable(s)}) that does \textcolor{orange}{NOT belong to the model}, but \textcolor{orange}{IS related with the endogenous variable} 
    \begin{enumerate}
      \item using the instrumental variable(s) (which we denote by $Z$), make the endogenous variable exogenous, which we call \textcolor{blue}{instrumented variable(s)}
      \item use the variation in the instrumented variable instead of the original endogenous variable to estimated the impact of the original variable
    \end{enumerate}
  \end{block}  
\end{frame}

\begin{frame}[c]
  \frametitle{IV estimation: Procedure}
  \begin{block}{Step 1: Idea}  
    using the instrumental variables, make the endogenous variable exogenous, which we call \textcolor{blue}{instrumented variable} 
  \end{block}
  \begin{block}{Step 1: Mathematically}  
  \begin{itemize}
    \item Regress the endogenous variable ($x_1$) on the instrumental variable(s) ($Z=\{z_1,z_2\}$, two instruments here) and all the other exogenous variables that you do not intend to instrument,
    \begin{align*}
      x_1 = \alpha_0 + \sigma_2 x_2 + \alpha_1 z_1 +\alpha_2 z_2 + \mu     
    \end{align*}   
    \item obtain the predicted value of $x$ from the regression
      \begin{align*}
        \hat{x}_1 = \hat{\alpha}_0 + \hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 + \hat{\alpha}_2 z_2
      \end{align*}
  \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[t]
  \frametitle{IV estimation: Procedure}
  \begin{block}{Step 2: Idea}  
    use the variation in the instrumented variable instead of the original endogenous variable to estimated the impact of the original variable 
  \end{block}
  \begin{block}{Step 2: Mathematically}  
  Regress the dependent variable ($y$) on the instrumented variable ($\hat{x}-1$),
    \begin{align*}
      y= \beta_0 + \beta_1 \hat{x_1}+ \beta_2 x_2 + \varepsilon     
    \end{align*}   
  to estimate the coefficient on $x$ in the original model
  \end{block}
\end{frame}

\begin{frame}[c]
  \frametitle{When does IV work?}
  \begin{block}{Question}  
    What are the conditions under which IV estimation is consistent?
  \end{block} 
  
\end{frame}

\begin{frame}[c]

  \frametitle{Conditions under which IV estimation is consistent: part I}
  \begin{block}{Estimation Procedure}  
  \vspace{-0.6cm}
    \begin{align*}
      \mbox{Step 1:} &\;\; \hat{x}_1 = \hat{\alpha}_0 +\hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 + \hat{\alpha}_2 z_2  \\
      \mbox{Step 2:} &\;\; y = \beta_0 + \beta_1 \hat{x_1}+ \beta_2 x_2 + \varepsilon     
    \end{align*}
  \end{block}
  \only<2->{\begin{block}{Question}  
    What happens if $Z$ have no power to explain $x_1$ ($E[\hat{\alpha}_1]=0$ and $E[\hat{\alpha}_2]=0$)? 
    \begin{itemize}
      \item $\hat{x}_1=\hat{\alpha}_0+\hat{\sigma}^2 x_2$ 
      \item $\hat{\beta}_1?$
    \end{itemize}
  \end{block}}
  \only<3->{\begin{block}{Condition I}  
    \textcolor{blue}{The instrument(s) $Z$ have jointly significant explanatory power on the endogenous variable $x_1$ \textcolor{orange}{after} you control for all the other exogenous variables (here $x_2$)}
  \end{block}}
\end{frame}


\begin{frame}[c]
  \only<1-2>{\begin{block}{The Model}  
  \vspace{-0.6cm}
  \begin{align*}
    y=\beta_0 + \beta_1 x_1 + \beta_2 x_2 + u
  \end{align*}
  \vspace{-0.6cm}
  \begin{itemize}
    \item $x_1$ is endogenous: $E[u|x_1] \ne 0$ (or $Cov(u,x_1)\ne 0$)
    \item $x_2$ is exogenous: $E[u|x_1] = 0$ (or $Cov(u,x_1) = 0$)
  \end{itemize}
  \end{block}}

  \only<2-3>{
  \begin{block}{Examination}  
    Plugging in $x_1 = \hat{\alpha}_0 + \hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 +\hat{\alpha}_2 z_2 + \hat{\mu}$ into the original model,
    \begin{align*}
      y   = & \beta_0 + \beta_1 (\hat{\alpha}_0 + \hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 +\hat{\alpha}_2 z_2 + \hat{\mu}) + u \\
          = & \beta_0 + \beta_1 \hat{x}_1 \;\; (=\hat{\alpha}_0 + \hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 +\hat{\alpha}_2 z_2) +\beta_2 x_2 \\
         & + v \;\; (=\beta_1 \hat{\mu} + u) 
    \end{align*}
  \end{block}
  } 

  \only<3-4>{
  \begin{block}{Condition II}  
  Any of the instruments $Z$
    \begin{itemize}
      \item do not belong in the true model of $y$, \textcolor{blue}{and}
      \item are not correlated with the error term ($u$)
    \end{itemize}
  \end{block}
  } 

  % \only<3-4>{\begin{block}{Conditions under which IV estimation is consistent: part II}  
  % \vspace{-0.6cm}
  % \begin{align*}
  %   & E[v|\hat{x}_1] = 0 \\
  %   & \Rightarrow E[\beta_1 \hat{\mu} + u|\hat{x}_1] = 0 \\
  %   & \Rightarrow E[\beta_1 \hat{\mu} + u|\hat{\alpha}_0 + \hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 +\hat{\alpha}_2 z_2] = 0 
  % \end{align*}
  % \end{block}}

  % \only<4-5>{\begin{block}{Sufficient conditions}  
  % \begin{itemize}
  %   \item $E[\hat{\mu}|z_1,z_2,x_2] = 0$: all the instruments and the other included instruments are uncorrelated with the residuals of the first stage (\textcolor{blue}{automatically satisfied})
  %   \item $E[u|z_1,z_2,x_2] = 0$: all the instruments and the other included instruments are uncorrelated with the error term of the second stage (\textcolor{blue}{$Cov(x_2,u)=0$} by assumption)
  % \end{itemize}
  % \end{block}}

  \only<4->{
  \begin{block}{Understanding Condition II}  
    \begin{itemize}
      \item If $z_i$ (here $i=1,2$) is part of the error term $u$, that is $z_i$ has an explanatory power after you control for all the independent variables and all the other important unobservables (whatever in $u$ other than $Z$), the condition is necessarily violated
      (\textcolor{blue}{$z_i$ should have been included in the original model in the first place!!}) 
      \item Even if $z_i$ has no explanatory power, if $z_i$ is correlated with the important unobservables (whatever in $u$), the above condition is violated
    \end{itemize} 
  \end{block}
  }
\end{frame}


\begin{frame}[c]
  \begin{block}{Conditions under which IV estimation is consistent}  
    \begin{itemize}
      \item \textcolor{blue}{the instrument $z$ is related with $x$: $Cov(x,z)\ne 0$}
      \item \textcolor{blue}{the instrument $z$}
      \begin{itemize}
        \item \textcolor{blue}{does not belong in the true model of $y$}
        \item \textcolor{blue}{is not correlated with the error term ($u$)}
      \end{itemize}
    \end{itemize}
  \end{block} 
  \begin{block}{Important}  
    \begin{itemize}
      \item Condition I is always testable
      \item Condition II is \textcolor{orange}{NOT} testable (unless you have more instruments than endogenous variables)
    \end{itemize}
  \end{block}
\end{frame}

% \begin{frame}[c]
%   \title{Instrumental Variable (IV) Estimation}
%   \author{}
%   \date{}
%   \maketitle
% \end{frame}

\begin{frame}[c]
  \frametitle{An Example}
  \begin{block}{The model}  
  \vspace{-0.6cm}
    \begin{align*}
      log(wage) = \beta_0 + \beta_1 educ + \beta_2 exper + v \;\; (=\beta_3 ability + u)
    \end{align*}   
  \end{block} 
  \begin{block}{Question}  
    What conditions would a good instrument ($z$) satisfy?
  \end{block}
  \begin{block}{Condition}  
  \begin{itemize}
    \item $z$ has explanatory power on $educ$ \textcolor{blue}{after} you control for the impact of $epxer$ on $educ$
    \item $z$ is uncorrelated with $v$ ($ability$ and all the other important unobservables)
  \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[c]
  \begin{block}{The model}  
  \vspace{-0.6cm}
    \begin{align*}
      log(wage) = \beta_0 + \beta_1 educ + \beta_2 exper + v \;\; (=\beta_3 ability + u)
    \end{align*}    
  \end{block}
  \only<1-1>{\begin{block}{An example of instruments}  
  \textcolor{blue}{The last digit of an individual's Social Security Number?} (this has been actually used in some journal articles) 
  \begin{itemize}
    \item Is it uncorrelated with $v$ ($ability$ and all the other important unobservables)?
    \item does it have explanatory power on $educ$ \textcolor{blue}{after} you control for the impact of $epxer$ on $educ$?
  \end{itemize}
  \end{block}}
  \only<2-2>{\begin{block}{An example of instruments}  
  \textcolor{blue}{IQ?} 
  \begin{itemize}
    \item Is it uncorrelated with $v$ ($ability$ and all the other important unobservables)?
    \item does it have explanatory power on $educ$ \textcolor{blue}{after} you control for the impact of $epxer$ on $educ$?
  \end{itemize}
  \end{block}}
  \only<3-3>{\begin{block}{An example of instruments}  
  \textcolor{blue}{Mother's education?} 
  \begin{itemize}
    \item Is it uncorrelated with $v$ ($ability$ and all the other important unobservables)?
    \item does it have explanatory power on $educ$ \textcolor{blue}{after} you control for the impact of $epxer$ on $educ$?
  \end{itemize}
  \end{block}}
  \only<4-4>{\begin{block}{An example of instruments}  
  \textcolor{blue}{Number of siblings?} 
  \begin{itemize}
    \item Is it uncorrelated with $v$ ($ability$ and all the other important unobservables)?
    \item does it have explanatory power on $educ$ \textcolor{blue}{after} you control for the impact of $epxer$ on $educ$?
  \end{itemize}
  \end{block}}
\end{frame}

% \begin{frame}[c]
%   \frametitle{IV estimator}
%   \begin{align*}
%     & y = \beta_0+\beta_1 x + u \\
%     \Rightarrow & Cov(y,z) = Cov(\beta_0+\beta_1 x + v,z) \\ 
%     \Rightarrow & Cov(y,z) = \beta_1 Cov(x,z) + Cov(u,z)  
%   \end{align*}
%   If $Cov(z,u)=0$ (Condition II), then
%   \begin{align*}
%    Cov(y,z) = \beta_1 Cov(x,z) \\
%    \beta_1 = Cov(y,z)/Cov(x,z) 
%   \end{align*}
%   If $Cov(z,x)\ne 0$, then $\beta_1$ is a finite value (not infinite)
%   \only<2->{\begin{block}{IV estimator}  
%   \vspace{-0.4cm}
%     \begin{align*}
%       \hat{\beta}_{iv} = \frac{\sum_{i=1}^n(z_i-\bar{z})(y_i-\bar{y})}{\sum_{i=1}^n(z_i-\bar{z})(x_i-\bar{x})}   
%     \end{align*} 
%   \end{block}}
% \end{frame}


% \begin{frame}[c]
%   \begin{block}{IV estimator}  
%   \vspace{-0.4cm}
%     \begin{align*}
%       \hat{\beta}_{IV} = \frac{\sum_{i=1}^n(z_i-\bar{z})(y_i-\bar{y})}{\sum_{i=1}^n(z_i-\bar{z})(x_i-\bar{x})}
%     \end{align*} 
%   \end{block}
%   \begin{block}{Notes}  
%     \begin{itemize}
%       \item It looks very similar to the estimator of the coefficient on the slope of $x$ in the univariate regression!
%       \item If $x$ is the instrument $z$, $\hat{\beta}_{IV}$ reduces to the OLS estimator
%     \end{itemize}
%   \end{block}
% \end{frame}

\begin{frame}[c]
  \begin{block}{Two-stage least squares estimator (2SLS)}
  \vspace{-0.6cm}
    \begin{align*}
      \mbox{Step 1:} &\;\; \hat{x}_1 = \hat{\alpha}_0 +\hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 + \hat{\alpha}_2 z_2  \\
      \mbox{Step 2:} &\;\; y = \beta_0 + \beta_1 \hat{x_1}+ \beta_2 x_2 + \varepsilon     
    \end{align*}
    \textcolor{blue}{it is called the two-stage least squares (2SLS) estimation because it involves two stages of OLS}
  \end{block}  
  \only<2->{
  \begin{block}{Note}  
  \begin{itemize}
    \item 2SLS is a good way to understand why and how instrumental variable estimation works
    \item But, IV estimation can be done in one-step (see the textbook if you are interested) 
  \end{itemize}
  \end{block}
  }
\end{frame}

%===================================
% Implementation
%===================================
\title{Instrumental variable (IV) estimation implementation in $R$ by example}
\author{}
\date{}

\begin{frame}
\titlepage
\end{frame}



\begin{frame}[c,fragile]
  \begin{block}{Model}  
  \vspace{-0.6cm}
    \begin{align*}
      log(wage) = \beta_0 + \beta_1 educ + \beta_2 exper + v \;\; (=\beta_3 ability + u)
    \end{align*} 
  \vspace{-0.6cm}
    \begin{itemize}
      \item endogenous included variable ($x_1$) is $educ$
      \item exogenous included variable ($x_2$) is $exper$
      \item we use the number of siblings ($sibs$) and father's education (feduc) as the instruments ($Z$)
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[c]
 \begin{block}{Some notes on terminology}  
    \begin{itemize}
      \item exogenous included variable(s) ($exper$) are also called \textcolor{blue}{included instruments}
      \item variables that you think can be excluded from the model ($sibs$ and $feduc$) are also called \textcolor{blue}{excluded instruments}
      \item we refer to the collection of included and excluded instruments as \textcolor{blue}{instruments}
      \item In the previous slides, when I say ``instruments,'' I meant ``excluded instruments.''
    \end{itemize}
\end{block} 
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: IV and 2SLS demonstration}

  <<iv_2sls_data, cache=TRUE, size='scriptsize'>>=
    #--- read the data ---#   
    data <- read.dta('WAGE2.dta')
    data_dt <- data.table(data)

    #--- take a look at the data ---#
    data_dt[,.(log(wage),educ,sibs,feduc)]
  @

  \end{block_code}
\end{frame}

% \begin{frame}[c,fragile]
%   \begin{block_code}{R code: IV by hand}

%   <<iv, cache=TRUE, size='scriptsize'>>=
%     #--- define z, x, and y ---#
%     z <- data_dt[,sibs] # instrument 
%     x <- data_dt[,educ] # endogenous variable
%     y <- data_dt[,log(wage)] # dependent variable

%     #--- IV ---#
%     nume <- cov(z,y)
%     denom <- cov(z,x)
%     beta_iv <- nume/denom
%     beta_iv
%   @
%   \end{block_code}
% \end{frame}

% \begin{frame}[c,fragile]
%   \begin{block_code}{R code: 2SLS by hand}

%   <<2sls, cache=TRUE, size='scriptsize'>>=
%     #--- 1st stage ---#
%     reg_1st <- lm(educ~exper+sibs+feduc,data=data_dt)
%     data_dt[,educ_hat:=reg_1st$fitted.value]

%     #--- summary of 1st stage ---#
%     summary(reg_1st)$coef

%     #--- 2nd stage ---#
%     reg_2nd <- lm(log(wage)~educ_hat+exper,data=data_dt) 

%     #--- summary of 2nd stage ---#
%     summary(reg_2nd)$coef
%   @
%   \end{block_code}
% \end{frame}



\begin{frame}[c]
  \begin{block}{Flow of IV estimation}  
    \begin{itemize}
      \item Identify endogenous variable(s) and included instrument(s) 
      \item Identify potential excluded instrument(s) 
      \item \textcolor{blue}{Argue} why the excluded instrument(s) you pick is uncorrelated with the error term (why just argue?)
      \item Once you decide what variable(s) to use as excluded instruments, \textcolor{blue}{test} whether the excluded instrument(s) is weak or not (first stage of $2SLS$)
      \item Do the second stage estimation and report the results
    \end{itemize} 
  \end{block}  
  \begin{block}{$AER$ packge in $R$}  
    $ivreg$ command from the $AER$ package does pretty much everything for you
  \end{block}
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: IV estmation using $ivreg$}
  <<ivreg, cache=TRUE, size='scriptsize',dependson='iv_2sls_data'>>=
  #--- IV estimation ---#
    iv_reg <- ivreg(log(wage)~educ+exper|exper+sibs+feduc,data=data_dt)
  @ 
  \end{block_code}
  \begin{block}{Syntax of $ivreg$}  
  \vspace{-0.6cm}
  \begin{align*}
    ivreg(dep\_var \sim indep\_vars|instruments,data)
  \end{align*}
  \vspace{-0.6cm}
  \begin{itemize}
    \item $indep\_vars$: all the independent variables in the model (endogenous variables and included instruments)
    \item $instruments$: instruments (included and excluded instruments) 
  \end{itemize}
  \end{block}
\end{frame}
 
\begin{frame}[c,fragile]
  <<ivreg_sum, cache=TRUE, size='scriptsize',dependson='ivreg'>>=
  summary(iv_reg,diagnostics=TRUE)
  @
\end{frame} 

\begin{frame}[c,fragile]
  \begin{block}{Comparison with OLS}  
    <<ols_2sls, echo=FALSE, cache=TRUE, size='scriptsize',results='asis',dependson='ivreg'>>=
    #--- OLS ---#  
    reg_ols <- lm(log(wage)~educ+exper,data=data_dt)

    #--- Stargaze ---#  
    stargazer(reg_ols,iv_reg,single.row=TRUE,omit.stat=c('all'),table.layout='-ldc-t-',type='latex',column.labels=c('OLS','IV'))
    @
  \end{block}
  \begin{block}{Question}  
    Do you think $sibs$ and $feduc$ are good instruments?
    \begin{itemize}
      \item Condition I: weak instruments?
      \item Condition II: uncorrelated with the error term?
    \end{itemize}
  \end{block}
\end{frame}


\begin{frame}[c]
\begin{block}{Diagnostics (see the bottom of the summary of the IV estimation)}  
  \begin{itemize}
    \item Weak instruments test:
    \item Wu-Hausman test:
    \item Sargan (Overidentification) test: later
  \end{itemize}
\end{block}
\end{frame}

\begin{frame}[c]
  \begin{block}{Weak instruments test}  
    Test of Condition I:
    \begin{itemize}
      \item $H_0:$ the excluded instrument(s) is weak (the instrument does not explain the endogenous variable)
      \item $H_1:$ the excluded instrument(s) is not weak 
    \end{itemize}
  \end{block}
  \begin{block}{1st stage}  
  \begin{itemize}
    \item Run the regression on the following model
    \begin{align*}
      educ = \alpha_0 + \alpha_1 exper + \alpha_2 sibs + \alpha_3 feduc + v  
    \end{align*}
    \item test the joint significance of $\alpha_2$ and $\alpha_3$ ($F$-test)
  \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[c]
  \begin{block}{Notes}  
  \begin{itemize}
    \item It is generally recommended that you have $F$-stat of over $10$ (this is not a clear-cut criteria that applied to all the empirical cases)
    \item Even if you reject the null if $F$-stat is small, you may have a problem
    \item You know nothing about if your excluded instruments satisfy Condition II. 
    \item If you cannot reject the null, it is a strong indication that your instruments are weak. Look for other instruments.
    \item Always, always report this test. There is no reason not to. 
  \end{itemize}
  \end{block} 
\end{frame}

\begin{frame}[c]
  \begin{block}{Wu-Hausman test}  
    Test of whether OLS is consistent:
    \begin{itemize}
      \item $H_0:$ OLS and IV coefficient estimations produce the same results
      \item $H_1:$ OLS and IV coefficient estimations produce different results 
    \end{itemize}
  \end{block} 
  \only<1-1>{
  \begin{block}{Idea}  
    If OLS is consistent, OLS and IV (which is supposed to be consistent) should produce similar coefficient estimates
  \end{block}
  \begin{block}{Procedure}  
    \begin{itemize}
      \item run OLS
      \item run IV
      \item compare them
    \end{itemize}
  \end{block}
  }
  \only<2->{\begin{block}{Important}  
  \begin{itemize}
    \item This test is only valid if your excluded instruments are valid, meaning they satisfy Conditions I and II
    \item This test is \textcolor{blue}{NOT} a test of whether your excluded instruments are valid!
  \end{itemize}
    
  \end{block}}
\end{frame}

\begin{frame}[c]
  \begin{block}{Notes}  
    When OLS and IV are both consistent because none of the independent variables are actually exogenous, $OLS$ is more efficient than $IV$
  \end{block}
  \begin{block}{IV}  
  \vspace{-0.6cm}
    \begin{align*}
      y = \beta_0 + \beta_1 \hat{x_1}+ \beta_2 x_2 + \varepsilon     
    \end{align*} 
    \vspace{-0.6cm}
    \begin{itemize}
      \item $\hat{x}_1 = \hat{\alpha}_0 +\hat{\sigma}_2 x_2 + \hat{\alpha}_1 z_1 + \hat{\alpha}_2 z_2$
      \item $x_1=\hat{x}_1+\hat{\mu} \;\;\mbox{(=residual)}$
    \end{itemize}
  \end{block}
  \begin{block}{OLS}  
  \vspace{-0.6cm}
  \begin{align*}
  y = \beta_0 + \beta_1 x_1+ \beta_2 x_2 + \varepsilon
  \end{align*}
  \end{block}
  \begin{block}{Intuition}  
     In the first stage regression, you discarded the information you could have used: $\hat{\mu}$ (residual) 
   \end{block} 
\end{frame}

\begin{frame}[c]
  \begin{block}{Sargan test}  
    Test of whether all the instruments (included and excluded instruments) are uncorrelated with the error term
    \begin{itemize}
      \item $H_0:$ all the instruments are uncorrelated with the error term
      \item $H_1:$ at least one of the instruments are uncorrelated with the error term 
    \end{itemize}
  \end{block} 
  \begin{block}{Note}  
    \begin{itemize}
      \item this test can be done (reported) only when there are more instruments than endogenous variables
      \item in general people do not believe this test because of its fragility 
      \item you really need to convince your readers why your excluded instruments are valid by argument (common practice the economics literature)
    \end{itemize}
  \end{block}
\end{frame}

% \begin{frame}[c,fragile]
%   <<ivreg_stargaze, cache=TRUE, size='scriptsize',results='asis'>>=
%   stargazer(iv_reg,type='latex')
%   @
% \end{frame} 


\begin{frame}[c,fragile]
  \frametitle{Consequences of weak instruments via MC simulation}

  \begin{block_code}{R code: setup}

  <<weak, size='scriptsize'>>=
    #--- setup ---#   
    set.seed(73289)
    N <- 500 # number of observations 
  @

  \end{block_code}

  
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: data generating process}

  <<weak_data_gen, size='scriptsize', dependson='weak'>>=
    # the term shared by the endogenous variable and the error term
    u_common <- runif(N) 

    # the term shared by the endogenous variable and instruments
    z_common <- runif(N) 

    # the endogenous variable
    x_end <- u_common + z_common + runif(N) 

    # strong instrument
    z_strong <- z_common + runif(N)

    # weak instrument
    z_weak <- 0.01*z_common + 0.99995*runif(N)

    # error term
    u <- u_common + runif(N)

    # dependent variable
    y <- x_end + u
    
    # put together a dataset
    data <- data.table(y,x_end,z_strong,z_weak)
  @

  \end{block_code}
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: Correlation}

  <<exp_weak, cache=TRUE, size='scriptsize', dependson='weak_data_gen'>>=
    cor(data[,.(x_end,u,z_strong,z_weak)])
  @

  \end{block_code}
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: IV estimation comparisons}
  <<iv_coed, cache=TRUE, size='scriptsize', dependson='weak_data_gen'>>=
     #--- IV estimation (strong) ---#
     iv_strong <- ivreg(y~x_end|z_strong,data=data)
     iv_strong_sum <- summary(iv_strong,diagnostics=TRUE)

     #--- IV estimation (weak) ---#
     iv_weak <- ivreg(y~x_end|z_weak,data=data)
     iv_weak_sum <- summary(iv_weak,diagnostics=TRUE)
  @ 
  \end{block_code}
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: IV estimation coefficients comparisons}
  <<iv_coef_comp, cache=TRUE, size='scriptsize', dependson='weak_data_gen'>>=
     #--- coefs (strong) ---#
     iv_strong_sum$coef

     #--- coefs (weak) ---#
     iv_weak_sum$coef
  @ 
  \end{block_code}
  \only<2->{\begin{block}{Any notable differences?}  
    \only<3->{The coefficient estimate on $x\_end$ is far away from the true value}
  \end{block}}
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: IV estimation diagnostics comparisons}
  <<iv_diag_comp, cache=TRUE, size='scriptsize', dependson='weak_data_gen'>>=
     #--- diagnostics (strong) ---#
     iv_strong_sum$diagnostics

     #--- diagnostics (weak) ---#
     iv_weak_sum$diagnostics
  @ 
  \end{block_code}
  \only<2->{\begin{block}{Any notable differences?}  
    \only<3->{Wu-Hausman test no longer significant at the $5\%$ level (recall that the test is invalid when IV is inconsistent)}
  \end{block}}
\end{frame}


\begin{frame}[c,fragile]
  \begin{block_code}{R code: IV estimation lots of times}

  <<weak_exps, cache=TRUE, size='scriptsize'>>=
  B <- 1000 # the number of experiments
  beta_hat_store <- matrix(0,B,2) # storage of beta hat

  for (i in 1:B){

    #--- data generation ---#
    u_common <- runif(N) 
    z_common <- runif(N) 
    x_end <- u_common + z_common + runif(N) 
    z_strong <- z_common + runif(N)
    z_weak <- 0.01*z_common + 0.99995*runif(N)
    u <- u_common + runif(N)
    y <- x_end + u
    data <- data.table(y,x_end,z_strong,z_weak)

    #--- IV estimation with a strong instrument ---#
    iv_strong <- ivreg(y~x_end|z_strong,data=data)
    beta_hat_store[i,1] <- iv_strong$coef['x_end']

    #--- IV estimation with a weak instrument ---#
    iv_weak <- ivreg(y~x_end|z_weak,data=data)
    beta_hat_store[i,2] <- iv_weak$coef['x_end']
  }
  @

  \end{block_code}
\end{frame}

\begin{frame}[c,fragile]
  \begin{block_code}{R code: Visualization of the results}

  <<viz, eval=FALSE, size='scriptsize'>>=
    melted <- melt(data.table(beta_hat_store))
    melted[variable=='V1',variable:='Strong']
    melted[variable=='V2',variable:='Weak']

    ggplot(data=melted) +
      geom_density(aes(x=value,fill=variable),alpha=0.3) +
      geom_vline(xintercept=1,color='red') +
      scale_fill_discrete(name='') +
      theme(
      legend.position='bottom'
      ) 
  @

  \end{block_code}
\end{frame}

\begin{frame}[c,fragile]

  <<viz_2, echo=FALSE, cache=TRUE, size='scriptsize'>>=
    melted <- melt(data.table(beta_hat_store))
    melted[variable=='V1',variable:='Strong']
    melted[variable=='V2',variable:='Weak']

    ggplot(data=melted) +
      geom_density(aes(x=value,fill=variable),alpha=0.3) +
      geom_vline(xintercept=1,color='red') +
      scale_fill_discrete(name='') +
      theme(
      legend.position='bottom'
      ) 
  @

\end{frame}

\begin{frame}[c,fragile]

  \begin{block_code}{R code: Visualization of the results}
  <<viz_3, eval=FALSE, cache=TRUE, size='scriptsize'>>=
    ggplot(data=melted[abs(value)<3,]) +
      geom_density(aes(x=value,fill=variable),alpha=0.3) +
      geom_vline(xintercept=1,color='red') +
      scale_fill_discrete(name='') +
      theme(
      legend.position='bottom'
      ) 
  @
  \end{block_code}

\end{frame}

\begin{frame}[c,fragile]

  <<viz_4, echo=FALSE, cache=TRUE, size='scriptsize'>>=
    ggplot(data=melted[abs(value)<3,]) +
      geom_density(aes(x=value,fill=variable),alpha=0.3) +
      geom_vline(xintercept=1,color='red') +
      scale_fill_discrete(name='') +
      theme(
      legend.position='bottom'
      ) 
  @

\end{frame}

\begin{frame}[c]
  \frametitle{IV estimation and heteroskedasticity}
  \begin{block}{Heteroskedastic Error}  
    Heteroskedaistic error has similar consequences as we saw earlier for OLS estimation
    \begin{itemize}
      \item biased estimation of the standard error of the coefficient estimators 
      \item invalid testing
    \end{itemize}   
  \end{block}  
  \begin{block}{In R}  
    We can simply add $vcov=sandwich$ option to the summary of IV regression results
  \end{block}
\end{frame}

\begin{frame}[c,fragile]
  
  \begin{block_code}{R code: Heteroskedasticity-robust se}
  <<het, cache=TRUE, size='scriptsize'>>=
  #--- IV estimation ---#
  iv_reg <- ivreg(log(wage)~educ+exper|exper+sibs+feduc,data=data_dt)

  #--- heteroskedasticity-robust se ---#
  sum_iv <- summary(iv_reg,diagnostics=TRUE,vcov=sandwich)
  sum_iv$vcov
  @
  \end{block_code}

\end{frame}

\begin{frame}[c,fragile]
  
  \begin{block_code}{R code: stargaze with heteroskedasticity-robust se}

  <<het_stargaze, eval=FALSE, cache=TRUE, size='scriptsize'>>=
  #--- recover the standard error ---#
  robust_se <- sqrt(diag(sum_iv$vcov))

  #--- stargazer ---#
  stargazer(iv_reg,se=list(robust_se),type='html',single.row=TRUE)
  @
  \end{block_code}

  <<het_stargaze_disp, echo=FALSE, cache=TRUE, size='scriptsize', results='asis'>>=
  #--- recover the standard error ---#
  robust_se <- sqrt(diag(sum_iv$vcov))

  #--- stargazer ---#
  stargazer(iv_reg,se=list(robust_se),type='latex',single.row=TRUE)
  @

\end{frame}


\end{document}


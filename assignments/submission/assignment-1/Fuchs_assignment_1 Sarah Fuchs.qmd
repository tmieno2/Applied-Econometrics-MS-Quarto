---
title: "Assignment 1 (<span style='color:blue'>Score: /10 </span>)"
author: "Sarah Fuchs"
format:
  html:
    number-sections: true
    number-depth: 1
    theme: flatly
    toc: true
execute:
  echo: true
  message: false
  warning: false
---

```{r setup_not_remove, echo=FALSE, include = F}
library(knitr)

# setwd(here("AssignmentsInstructor/Assignment_1"))
opts_chunk$set(
  echo = TRUE,
  comment = NA,
  message = FALSE,
  warning = FALSE,
  tidy = FALSE,
  #--- figure related ---#
  fig.align = "center",
  fig.width = 5,
  fig.height = 4
  # dev='pdf'
)
```

# Instruction

Due date is <span style='color:blue'>October, 11th </span> <span style='color:red'>before</span> the lab session on that day, in which this assignment is reviewed by the TA. Submission after the deadline would result in a heavy discount on the score. 

Please submit your assignment (both the qmd and the resulting html files) using the following [Dropbox submission request link](https://www.dropbox.com/request/QoEGkBxBSn1xvmYhJbe1). Name your qmd file using the following convention: `lastname_assignment_1.qmd`. For example, it would be `Mieno_assignment_1.qmd` for me. 

I do not accept any hand-written answers (you will get score of zero for that problem). Leave all the R codes and results in your answer (where appropriate) for the computer exercises. If your R codes are not provided, you will get score of 0 for that question.

You are encouraged to discuss the problems with your classmates. However, I would recommend that you do so after you try all the problems yourself. You would be simply doing disservice to yourself if you resort to your friends' help immediately, depriving you of important opportunities to think carefully about what we have learned and understand them through solving the problems. 

<!-- <span style="background:yellow">(you may remove this part when you submit your work)</span>  -->
<!-- Instruciton ends here -->

------

<!-- Non-computer Exercises --> 
# Non-computer Exercises

## Problem 1 

Let `kids` denote the number of children ever born to a woman, and let `educ` denote years of education for the woman. A simple model relating fertility to years of education is
$$
kids=\beta_0+\beta_1 educ+u
$$
where $u$ is the unobserved error.

------

(i) What kinds of factors are contained in $u$? Are these likely to be correlated with level of education?

#--Answer Problem 1 (i)--#

"In a model such as the one in Problem 1, $u$ represents all of the un-observable, un-explainable parts of $y$. In this model, $u$ contains the unobserved and unexplained parts of $kids$ that cannot be explained by the $x$ variable $educ$. It is the error term and could include variables such as the woman's health/fertility health, employment status, marital status, financial status, etc.

With such a simple regression and so few variables specifically identified, it is difficult to not have at least one factor which is contained in $u$ to be correlated with $x$, thus affecting $y$. Therefore, $u$ is likely to be correlated with level of education."

------

(ii) Will a simple regression analysis uncover the ceteris paribus effect of education on fertility? Explain.

#--Answer Problem 1 (ii)--#

"Ceteris Paribus -- "other (relevant) factors being equal" (Wooldridge. "Introductory Econometrics: A Modern Approach, 4e".2009.pg 12) -- is an important concept when determining causal effect of $x$ on $y$ ($educ$ on $kids$). If $u$ (the un-observables) can be held constant, we would be able to effectively measure the effect of $educ$ on the expected value of $kids$. However, in a simple model such as 
$kids=\beta_0+\beta_1 educ+u$, it is highly likely that at least some of the un-observed variables contained in $u$ will be correlated with $x$ (years of education). Assuming a women does consider her financial status (or available finances) when deciding on whether to continue her education (or how much education she will pursue), $u$ is correlated with $x$ (financial status correlated with $educ$). More money available could contribute to a higher ability to continue schooling for a longer period of time, which could affect the amount of reproductive years of the woman or the desire to have kids, thus affecting the ultimate value of the $y$ variable $kids$. With such a simple model it is hard to find non-correlation between the $x$ variable and $u$. It is difficult to satisfy the zero conditional mean of $E(u|x)=0$ in order to achieve non-correlation."  


## Problem 6

Using data from 1988 for houses sold in Andover, Massachusetts, from Kiel and McClain (1995), the following equation relates housing price (`price`) to the distance from a recently built garbage incinerator (`dist`):
$$
\begin{aligned}
\widehat{log(price)} = 9.40 + 0.312\times log(dist)\\
n=135,\;\; R^2 = 0.162
\end{aligned}
$$

------

(i) Interpret the coefficient on $log(dist)$. Is the sign of this estimate what you expect it to be?

#--Answer Problem 6 (i)--#

"The coefficient on $log(dist)$ (0.312) represents $\beta_1$ and tells us the elasticity of $price$ ($y$ variable) with respect to $dist$ ($x$ variable). That is, it tells us that with a 1 increment increase (1% increase) in $dist$ (distance from garbage incinerator), $price$ (price of house in question) will increase by the value of $\beta_1$, or approximately .312%, ceteris paribus (everything else fixed).

The sign of the estimate is what I would expect, considering as the distance from the garbage incinerator increases, the resulting price of the house also increases (more distance from garbage incinerator equals a more desirable location to live equals higher house prices)."

------

(ii) Do you think simple regression provides an unbiased estimator of the ceteris paribus elasticity of price with respect to dist? (Think about the city's decision on where to put the incinerator.)

#--Answer Problem 6 (ii)--#

"I do not believe that this simple regression represents and provides a good estimator of home price. Home prices are generally affected by variables other than just distance away from a garbage incinerator and it is those factors, encompassed in $u$ (the un-explainable and un-observable), that will also have an effect on the $y$ variable $price$ as it is difficult to satisfy $E(u|x)=0$."

------

(iii) What other factors about a house affect its price? Might these be correlated with distance from the incinerator?

#--Answer Problem 6 (iii)--#

"Some of these other factors which affect house price could very well be correlated with the distance from the incinerator. If it is assumed that, generally, people would not prefer to live close to a garbage incinerator if they have the financial means to live further away, then certain types, sizes, and trim levels of houses might be built closer to (or further from) the incinerator, thus leaving items such as the square footage of a house, as well as the level of quality of the existing internal furnishings and fixtures potentially correlated with the distance from the incinerator."

<!-- Computer Exercises --> 

# Computer Exercises



## Problem C1

The data in __401K.csv__ are a subset of data analyzed by Papke (1995) to study the relationship between participation in a 401(k) pension plan and the generosity of the plan. The variable `prate` is the percentage of eligible workers with an active account; this is the variable we would like to explain. The measure of generosity is the plan match rate, `mrate`. This variable gives the average amount the firm contributes to each worker's plan for each $1 contribution by the worker. For example, if $mrate= 0.50$, then a $1 contribution by the worker is matched by a $50$ cents contribution by the firm.


------

(i) Find the average participation rate and the average match rate in the sample of plans.

#--Answer Problem C1 (i)--#

```{r}

library(tidyverse)
library(haven)
library(fixest)
library(readr)

setwd("C:/Users/msfuc/OneDrive/Documents/Econometrics/Assignment 1")

pension_data <- readr::read_csv("401K.csv")

pension_data

#--Average Participation Rate:
y <- pension_data$prate
ave_prate <- mean(y)
ave_prate

#--Average Match Rate:
x <- pension_data$mrate
ave_mrate <- mean(x)
ave_mrate

```   

------

(ii) Now, estimate the simple regression equation
$$
\hat{prate}=\hat{\beta}_0+\hat{\beta}_1\cdot mrate
$$
and present the results using the `msummary()` function from the `modelsummary` package.



<br>

#--Answer Problem C1 (ii)--#

```{r}

library(modelsummary)

#--Running OLS--#

uni_reg_401K <- feols(prate ~ mrate, data = pension_data)
uni_reg_401K

summary(uni_reg_401K)

```

------

(iii) Interpret the intercept in your equation. Interpret the coefficient on mrate.

#--Answer Problem C1 (iii)--#

$\hat{\beta}_0 = 83.07546$

$\hat{\beta}_1 = 5.86108$

After running the simple regression on the data (pension_data), the estimated intercept returns a value of 83.07546. This number is $\hat{\beta}_0$ in the regression equation and is the constant term, or intercept parameter. The value of $\hat{\beta}_0 = 83.07546$ means that if the employer in this scenario does not contribute any amount as a match to the employee's pension plan ($mrate = 0$), the predicted participation rate ($\hat{prate}$) of eligible workers would be approximately 83%.

The coefficient on $mrate$ is found to be 5.86108 after running the regression. This number represents $\hat{\beta}_1$ in the regression equation and is interpreted to mean that for every 1% increase in $mrate$, the participation rate ($prate$) increases by approximately 5.86% of eligible workers.



(iv) Find the predicted prate when $mrate=3.5$. Is this a reasonable prediction? 
Explain what is happening here.


#--Answer Problem C1 (iv)--#


$\hat{prate}$ = 83.07546 + 5.86108(3.5)

```{r}
83.07546 + 5.86108 * 3.5 
```
When a company sets their pension plan match rate to 3.5%, the model is saying that the participation rate ($prate$) will increase by 20.51378% (5.86108 * 3.5). The value of the predicted participation rate ($\hat{prate}$ = 103.58924) doesn't really make sense and isn't a reasonable prediction since it is telling us that if the match rate ($mrate$) were 3.5%, over 100% of the eligible workers would participate. This isn't reasonable since a company can't have more workers participate than their eligible worker base.

------

(v) How much of the variation in prate is explained by `mrate`? Is this a lot in your opinion?

#--Answer Problem C1 (v)--#

The value of $R^2$ is the ratio of the explained variation compared to the total variation. As an equation, $R^2$ is equal to $SSE/SST$ (Expalined Sum of Squares/Total Sum of Squares). According to the regression processed earlier in part ii) of this problem, $R^2 = 0.074099$. If we take this output and multiply by 100 we can change it into a percentage, and thus the percentage of the sample variation in $y$ ($prate$) that is explained by $x$ ($mrate$). Therefore, according to the regression output, 7.4099% of the variation in $prate$ is explained by $mrate$.

I don't necessarily think that this amount of variation is a lot. Everyday living these days is quite expensive and an individual may feel that he/she needs the entire amount of compensation received for the work they do in order to meet daily living expense needs. If an employer offers a match to a retirement plan, the existence of the match and the level of the match could potentially play a very large role in whether a worker decides to parcel a bit of their earned wage to participate or not.


## Problem C2

The data set in __CEOSAL2.dta__ contains information on chief executive officers for U.S. corporations. The variable `salary` is annual compensation, in thousands of dollars, and `ceoten` is prior number of years as company CEO.


------

(i) Find the average salary and the average tenure in the sample. 

#--Answer Problem C2 (i)--#

```{r}

CEOSAL2_data <- haven::read_dta("CEOSAL2.dta")

CEOSAL2_data

```

Average Salary in thousands of dollars:

```{r}

y <- CEOSAL2_data$salary
ave_salary <- mean(y)

ave_salary

```
Average CEO Tenure:
(prior number of years as company CEO)

```{r}
x <- CEOSAL2_data$ceoten
ave_ceoten <- mean(x)

ave_ceoten

```

------

(ii) How many CEOs are in their first year as CEO (that is, ceoten 5 0)? What is the longest tenure as a CEO? [Hint: use the `filter()` and `nrow()` functions]

#--Answer Problem C2 (ii)--#

CEO's in First Year:

```{r}

CEO_firstyear <- dplyr::filter(CEOSAL2_data, ceoten == 0)

CEO_firstyear

nrow(CEO_firstyear)

```
Longest Tenure as CEO:

```{r}

CEO_longest_data <- dplyr::arrange(CEOSAL2_data, desc(ceoten), max(ceoten))%>%head()

CEO_longest_data

CEO_longest <- dplyr::filter(CEO_longest_data, ceoten == 37)

CEO_longest

```
Longest Tenure as CEO = 37 prior years

------

(iii) Estimate the simple regression model
$$
log(salary)=\beta_0+\beta_1\cdot ceoten +u
$$
and report your results in the usual form using the `msummary()` function. What is the (approximate) predicted percentage increase in salary given one more year as a CEO?

#--Answer Problem C2 (iii)--#

```{r}

#--Run OLS--#

uni_reg_CEOSAL2 <- feols(log(salary) ~ ceoten, data = CEOSAL2_data)


summary(uni_reg_CEOSAL2)

```

$\beta_0$ = 6.505498        $\beta_1$ = 0.009724

The approximate predicted percentage increase in salary given one more year as a CEO is .9% - almost 1% for an additional year of tenure for a CEO.

<br>


------

## Problem C8
To complete this exercise you need a software package that allows you to generate data from the uniform and normal distributions.



(i) Start by generating $500$ observations $x_i$ – the explanatory variable – from the uniform distribution with range $[0,10]$. (Most statistical packages have a command for the Uniform[0,1] distribution; just multiply those observations by 10.) What are the sample mean and sample standard deviation of the $x_i$?

#--Answer Problem C8 (i)--#

```{r}

#--Load fixest package--#

library(fixest)

#--generate data--#

set.seed(5338)

N <- 500  #observations
x1<- runif(N) #independent variable

x_i <- (x1 * 10)
x_i

```
Sample Mean:

```{r}

#--calculate sample mean--#

mean_x1 <- mean(x_i)
mean_x1

```

Sample Standard Deviation:

```{r}

#--calculate sample standard deviation--#

std_dev_x1 <- sd(x_i)
std_dev_x1

```


------

(ii) Randomly generate $500$ errors, $u_i$, from the Normal[0,36] distribution. (If you generate a Normal[0,1], as is commonly available, simply multiply the outcomes by six.) Is the sample average of the $u_i$ exactly zero? Why or why not? What is the sample standard deviation of the $u_i$?

#--Answer Problem C8 (ii)--#

```{r}

#--generate 500 errors--#

set.seed(5338)

N <- 500 #observations

mu <- rnorm(N) #common term, x & u

u <- rnorm(N) + mu #error

u_i <- (u*6)
u_i

```
Sample Average of $u_i$:

```{r}

#--Sample average of u_i--#

mean_u_i <- mean(u_i)
mean_u_i

```
The sample average of $u_i$ is not exactly zero, but on average it is really close to zero.


Sample Standard Deviation of $u_i$:

```{r}
#--Sample Standard Deviation of u_i--#

std_dev_u_i <-sd(u_i)
std_dev_u_i


```


------

(iii) Now generate the $y_i$ as
$$
y_i=1+2x_i+u_i 
$$
that is, the population intercept is one and the population slope is two. Use the data to run the regression of $y_i$ on $x_i$. What are your estimates of the intercept and slope? Are they equal to the population values in the above equation? Explain.


<br>


#--Answer Problem C8 (iii)--#

```{r}

x <- rnorm(N) + mu #independent variable

y <- 1+(2*x)+u #dependent variable

data <- data.frame(y=y, x=x)

#--OLS--#

reg <- fixest::feols(y ~ x, data = data)
reg 

```

------

(iv) Obtain the OLS residuals, $\hat{u}_i$, and verify that the following equations hold (subject to rounding error).

```{=tex}
\begin{align}
\sum_{i=1}^n \widehat{u}_i = 0 \\
\sum_{i=1}^n \widehat{u}_i \cdot x_i = 0 
\end{align}
```


#--Answer Problem C8 (iv)--#

I don't know how to write this code - I don't know how to pull the information from part (iii) to put it in code to arrive at the residuals. I believe I need to end up with $\hat{u}_i = {y}_i -(\hat{\beta}_0+ \hat{\beta}_1)$    $\hat{u}_i = 0.974352-(1+(2*2.551991)) = -5.12963$, but I don't know how to get there with R code.  My head is swimming in circles.

```{r}

```

------

(v) Compute the same quantities of the equations in the question above, but use the errors $u_i$ in place of the residuals. Now what do you conclude? $\sum_{i=1}^n u_i=0$?

#--Answer Problem C8 (v)--#

```{r}
#--errors sum of residuals--#

errors_sum_of_residuals <- sum(u_i)
errors_sum_of_residuals

```


```{r}
#--errors sum product--#

errors_sum_product <- sum(u_i * x_i)
errors_sum_product

```


------

(vi) Repeat parts (i), (ii), and (iii) with a new sample of data, starting with generating the $x_i$. Now what do you obtain for $\hat{\beta}_0$ and $\hat{\beta}_1$? Why are these different from what you obtained in part (iii)?


#--Answer Problem C8 (vi)--#

#--Repeat part (i) with new sample of data--#

```{r}

#--generate data--#

set.seed(7932)

N <- 500  #observations
x1_2<- runif(N) #independent variable

x_i2 <- (x1_2 * 10)
x_i2


```

Sample Mean:

```{r}

#--calculate sample mean--#

mean_x1_2 <- mean(x_i2)
mean_x1_2

```

Sample Standard Deviation:

```{r}

#--calculate sample standard deviation--#

std_dev_x1_2 <- sd(x_i2)
std_dev_x1_2

```

#--Repeat part (ii) with new sample of data--#

```{r}

#--generate 500 errors--#

set.seed(7932)

N <- 500 #observations

mu2 <- rnorm(N) #common term, x & u

u2 <- rnorm(N) + mu2 #error

u_i2 <- (u2*6)
u_i2

```

#--Repeat part (iii) with new sample of data--#

```{r}

x2 <- rnorm(N) + mu2 #independent variable

y2 <- 1+(2*x2)+u2 #dependent variable

data2 <- data.frame(y2=y2, x2=x2)

#--OLS--#

reg2 <- fixest::feols(y2 ~ x2, data = data2)
reg2 

```
$\hat{\beta}_0 = 1.07915$ and $\hat{\beta}_1 = 2.49159$

These numbers are slightly different than the original outcomes of parts (i), (ii), and (iii), because a new, different sample of data was utilized within the code. For the first round, set.seed(5338) was used, while the second round used a new sample of data with set.seed(7932). Either way, both numbers for ${\beta}_0$ were close (0.974352 vs 1.07915) and both numbers for ${\beta}_1$ were close (2.551991 vs 2.49159) to the model presented.

